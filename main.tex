\documentclass[12pt,letterpaper,english]{article}

\include{header}
\hypersetup{
	pdftitle = {%
		Decreasing Power Usage of
		Convolutional Neural Network Implementations
		on FPGAs
	},
	pdfauthor = {Clarity Shimoniak},
	pdfsubject = {EE 243 Project Proposal},
	pdfkeywords = {%
		computer vision, convolutional neural network, CNN, FPGA, Xilinx,
		Lattice, MNIST
	},
}


\addbibresource{cites.bib}
\addbibresource{cites-to-main.bib}
\addbibresource{cites-from-main.bib}
\newcommand{\citework}[1]{\citeauthor{#1} \autocite{#1}}
\newcommand{\citeworks}[2]{%
	\citeauthor*{#1} \autocite{#1} and \citeauthor*{#2} \autocite{#2}%
}
\newcommand{\citemoreworks}[3]{%
	\citeauthor*{#1} \autocite{#1},
	\citeauthor*{#2} \autocite{#2}, and
	\citeauthor*{#3} \autocite{#3}%
}


\begin{document}

\begin{center}
	{\LARGE%
		Decreasing Power Usage of
		Convolutional Neural Network Implementations
		on FPGAs
	} \\
	\vspace{6pt}
	Clarity Shimoniak
	\vspace{-18pt}
\end{center}

\section*{Key Publication}

In \citetitle*{main} \autocite{main}, \citeauthor{main} implement handwritten
digit recognition using the MNIST dataset on a Xilinx Artix 7 FPGA. Their
primary goal is to reduce the hardware resources usage and power consumption of
the system while maintaining acceptable performance.


\section*{Topic Introduction}

The high power usage of most CNN implementations limits their viability for
battery-powered applications. Additionally, large and expensive acceleration
hardware like GPUs limits their viability for consumer applications. Increasing
power efficiency and decreasing component cost would allow these models to be
deployed far more widely.


\section*{Planned Activities}

I plan to implement a system similar to \citeauthor*{main}'s using the Lattice
iCE40UP5k and a similar OmniVision camera. If time permits, I will also
implement the system on other Lattice FPGAs of slightly higher and lower specs
(LFE5U-25F-6 and iCE40LP1k respectively). Achieving similar results with these
parts would show that the approach is generalizable to lower-cost parts from
other manufacturers using an open source toolchain.


\section*{Related Publications}

\begin{itemize}
	\item \citework{madineni2023parameterizable} compare the results of their
	Verilog generator to \autocite{main} in order to showcase the potential of
	the Chisel HDL.
	\item \citework{baedorf2023reverse} reference \autocite{main} as a method of
	classification that was passed over for neural network analysis of abnormal
	breathing.
	\item \citework{phipps2023pre} contrast the performance of \autocite{main}
	against other similar models.
	\item \citeworks{pistellato2023quantization}{yan2023end} use \autocite{main}
	as an example of techniques by which performance of neural networks on FPGAs
	can be improved.
	\item \citeauthor{main} refers to
	SqueezeNet \autocite{iandola2016squeezenet},
	MobileNet \autocites{howard2017mobilenets}{sandler2018mobilenetv2},
	ShuffleNet \autocite{zhang2018shufflenet}, and
	ESPNet \autocite{mehta2018espnet}
	as examples of model size reduction.
	\item \citeauthor{main} compares results against those of
	\citemoreworks{yaozong2019design}{xiaokang2019design}{binfeng2019design},
	which use the heterogeneous Xilinx Zynq SoC platform and those of
	\citeworks{bingchen2019fpga}{hui2021convolutional},
	which use a Xilinx Spartan 6 and Artix 7 FPGAs respectively.
\end{itemize}


\newpage
\printbibliography


\end{document}
