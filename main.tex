\documentclass[12pt,letterpaper,english]{article}

\include{header}
\hypersetup{
	pdftitle = {%
		Decreasing Power Usage of
		Convolutional Neural Network Implementations
		on FPGAs
	},
	pdfauthor = {Clarity Shimoniak},
	pdfsubject = {EE 243 Project Proposal},
	pdfkeywords = {%
		computer vision, convolutional neural network, CNN, FPGA, Xilinx,
		Lattice, MNIST
	},
}


\addbibresource{cites.bib}
\addbibresource{cites-to-main.bib}
\addbibresource{cites-from-main.bib}
\newcommand{\citework}[1]{\citeauthor{#1} \autocite{#1}}
\newcommand{\citeworks}[2]{%
	\citeauthor*{#1} \autocite{#1} and \citeauthor*{#2} \autocite{#2}
}


\begin{document}

\begin{center}
	{\LARGE%
		Decreasing Power Usage of
		Convolutional Neural Network Implementations
		on FPGAs
	} \\
	\vspace{6pt}
	Clarity Shimoniak
	\vspace{-18pt}
\end{center}

\section*{Key Publication}

In \citetitle*{main}\autocite{main}, \citeauthor{main} implement handwritten
digit recognition using the MNIST dataset on a Xilinx Artix 7 FPGA. Their
primary goal is to reduce the hardware resources usage and power consumption of
the system while maintaining acceptable performance.


\section*{Topic Introduction}

The high power usage of most CNN implementations limits their viability for
battery-powered applications. Additionally, large and expensive acceleration
hardware like GPUs limits their viability for consumer applications. Increasing
power efficiency and decreasing component cost would allow these models to be
deployed far more widely.


\section*{Planned Activities}

I plan to implement a system similar to \citeauthor*{main}'s using the Lattice
iCE40UP5k and a similar OmniVision camera. If time permits, I will also
implement the system on other Lattice FPGAs of slightly higher and lower specs
(LFE5U-25F-6 and iCE40LP1k respectively). Achieving similar results with these
parts would show that the approach is generalizable to lower-cost parts from
other manufacturers using an open source toolchain.


\section*{Related Publications}

\begin{itemize}
	\item \citework{madineni2023parameterizable} propose a system implemented in
	the new Chisel hardware design language that claims improvements over
	\citetitle{main} and several similar implementation.
	\item \citework{baedorf2023reverse} reference \citetitle{main} as a method
	of classification that was passed over for neural network analysis of
	abnormal breathing.
	\item \citework{phipps2023pre} contrast the performance of \citetitle{main}
	against other similar models.
	\item \citeworks{pistellato2023quantization}{yan2023end} use
	\citetitle{main} as an example of techniques by which performance of neural
	networks on FPGAs can be improved.
	\item \citeworks{aydin2023fpga}{naufal2023comparative} use \citetitle{main}
	as a generic example of the significance of hardware acceleration for neural
	networks.
\end{itemize}


\newpage
\printbibliography


\end{document}
